{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Garbage in Garbage Out\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/UVADS/DS1001/blob/master/ddsbook/analytics-lab-IIa.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install statsmodels\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What we are going to do is create a linear model using old faithful data. Then we are going to add Gaussian noise iteratively to a dataset and pass the new noisy dataset to a the same linear regression model and track the ability of the model to learn the target as noise increases. \n",
    "\n",
    "1. Read this brief wiki on garbage in garbage out: [article](https://en.wikipedia.org/wiki/Garbage_in,_garbage_out)  \n",
    "\n",
    "2. Work through the below notebook, paying close attention to the comments and the outputs of the code. \n",
    "\n",
    "3. Answer the questions at the end as they relate to the process of adding noise to a dataset and then passing it to a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset we will be using is a well known measure of eruption and wait times for old faithful. \n",
    "# Take a look at the documentation \n",
    "# here: https://www.rdocumentation.org/packages/datasets/versions/3.6.2/topics/faithful\n",
    "\n",
    "\n",
    "# This is our data source (.tsv == tab separated), here we are creating a variable that holds the url to the data.\n",
    "# If you click the {x} in the ribbon to the left you will see the variables you have created.\n",
    "url=\"https://gist.githubusercontent.com/curran/4b59d1046d9e66f2787780ad51a1cd87/raw/9ec906b78a98cf300947a37b56cfe70d01183200/data.tsv\"\n",
    "\n",
    "\n",
    "# Here we are reading in the data, and use the \"tab\" as a separator so the data will be loaded \n",
    "# in correctly.  pd stands for pandas and \"pd.read_csv\" is the function we are \n",
    "# using to read in the data from the url.\n",
    "old_faith = pd.read_csv(url, sep='\\t')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a quick look at a scatter plot to get an idea of the distribution of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt (matplotlib.pyplot) is the library we are using to create our scatter plot.  We are using the \"scatter\" function, \n",
    "# and the alpha is the transparency of the dots.\n",
    "plt.scatter(old_faith.waiting,old_faith.eruptions, alpha=0.5)\n",
    "# here we are adding the labels to the x and y axis\n",
    "plt.ylabel(\"Eruption Seconds\")\n",
    "plt.xlabel(\"Waiting Minutes\")\n",
    "\n",
    "#this is the function that renders the plot\n",
    "plt.show()\n",
    "\n",
    "# Note the patterns that you see, (you'll need this for your submission) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next lets build a linear regression model to predict Eruption Length based on Waiting Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are using the statsmodels library to create a linear regression model. sm stands for statsmodels and OLS \n",
    "# stands for Ordinary Least Squares.  We are using the \"fit\" function to fit the model to the data.\n",
    "lm = sm.OLS(old_faith['waiting'],old_faith['eruptions']).fit()\n",
    "\n",
    "# Now we are printing out the summary of the model (lm). The summary function will give you the R2 measure, along with \n",
    "# other measures of model fit. \n",
    "lm.summary()\n",
    "\n",
    "#Using the R2 measure, how well does the model predict eruption length (scale of 0 to 1,\n",
    "#  where 1 is perfect, again needed for your submission)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we are creating \"noise\" that aligns to a normal or gaussian distribution, thus gaussian noise, to add to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu= mean and sigma = standard deviation, these are the inputs you will be changing\n",
    "mu, sigma = 0, .5 \n",
    "# We need to create noise with the same dimensions as the dataset (272,2), this will allow us \n",
    "# to combine them easily\n",
    "noise = np.random.normal(mu, sigma, [272,2])\n",
    "# The print function will print the first 5 rows of the noise array \n",
    "print(noise[0:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Really a small change, let's see what happens to model quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are adding the noise to the dataset\n",
    "old_faith_1=old_faith + noise\n",
    "\n",
    "#Create a new model with the noise added to the data\n",
    "lm_1 = sm.OLS(old_faith_1['waiting'],old_faith_1['eruptions']).fit()\n",
    "\n",
    "#Checking the R2 number, note what happens.\n",
    "lm_1.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's take a look at that same scatter plot but with the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(old_faith_1.waiting,old_faith_1.eruptions, alpha=0.5)\n",
    "plt.ylabel(\"Eruption Seconds\")\n",
    "plt.xlabel(\"Waiting Minutes\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Slowly change the standard deviation (increments of .25, stopping at 3.5), add the noise array to the dataset with each increase, re-run the model and see what happens with the R2 number, note the pace of change of the model (write it down).  \n",
    "\n",
    "#### Task 2: Following the same process above but instead adjust the mean to three different increasing increments but leave the standard dev at .05, note how this changes the model fit.  \n",
    "\n",
    "## Questions for submission: \n",
    "\n",
    "1. What patterns do you see in the original data (from the scatter plot)? \n",
    "\n",
    "2. How well did the first model fit the original data (from the model output)? \n",
    "\n",
    "3. What happens when you add the standard deviation oriented noise to the data, at what level does the model appear to degrade significantly?\n",
    "\n",
    "4. What happens when you add the mean noise to the data while holding the standard dev constant, does the model degrade at the same level as the standard deviation noise? Why or why not?\n",
    "\n",
    "5. Explain the concept behind noise versus signal as it relates to the old faithful dataset, how does this relate to garbage in garbage out?  \n",
    "\n",
    "6. Explain what the linear regression model is doing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
