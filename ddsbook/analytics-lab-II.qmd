---
title: "Garbage(Noise) in Garbage Out"
format: html
---


[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/UVADS/DS1001/blob/master/ddsbook/ex_boost_machine_example.ipynb) 




```{python}
# pip install statsmodels
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
import statsmodels.api as sm

```

## What we are going to do is add guassian noise itertatively to a dataset and then pass the new noisy dataset to a pretrained machine linear model and track the ability of the model to learn the target as noise increases. 

1. Read this brief article on garbage in garbage out and this brief article on guassian noise. 

2. Answer the questions below as they relate to model output and the articles. 


```{python}
# This is the dataset we will be using: classic eruption times for old faithful. Take a look at the documentation here: https://www.rdocumentation.org/packages/datasets/versions/3.6.2/topics/faithful


## This is our data source
url="https://gist.githubusercontent.com/curran/4b59d1046d9e66f2787780ad51a1cd87/raw/9ec906b78a98cf300947a37b56cfe70d01183200/data.tsv"


## Reading in the data, and use the "tab" as a separator so the data will be loaded in correctly.  pd stands for pandas and "pd.read_csv" is the function we are using to read in the data from the url.
old_faith = pd.read_csv(url, sep='\t')

```

## Let's take a quick look at a plot to get an idea of the distribution of the data. 

```{python}

plt.scatter(old_faith.eruptions, old_faith.waiting, alpha=0.5)
plt.xlabel("Eruption Time")
plt.ylabel("Waiting Time")

plt.show()

# Note the patterns that you see, (you'll need this for your submission) 
```

## Next lets build a simple model to predict Eruption Length based on Waiting Time 

```{python}
lm = sm.OLS(old_faith['waiting'],old_faith['eruptions']).fit()

lm.summary()

#Using the R2 measure, how well does the model predict (scale of 0 to 1, where 1 is perfect, again needed for your submission)
```


## Now what we are going to do is add "noise" to the dataset and then rerun the model and see what happens.
```{python}
# mu= mean and sigma =standard deviation
mu, sigma = 0, 1.5 
# creating a noise with the same dimension as the dataset (2,2) 
noise = np.random.normal(mu, sigma, [272,2]) 
print(noise[0:5])



```

## Really a small change, let's see what happens to the model quality
```{python}
old_faith_1=old_faith + noise

lm_1 = sm.OLS(old_faith_1['waiting'],old_faith_1['eruptions']).fit()

lm_1.summary()

```

## Now let's take a look at that same scatter plot but with the new data
```{python}
plt.scatter(old_faith_1.eruptions, old_faith_1.waiting, alpha=0.5)
plt.xlabel("Eruption Time")
plt.ylabel("Waiting Time")

plt.show()



```

## Task 1: Slowly change the standard deviation (increases of .25) and see what happens with the R2 number, note the pace of change of the model.  

## Task 2: Adjust the mean but leave the standard dev low, note how this effects the model.  

Questions for submission: 
1. What patterns do you see in the data?

1. Explain the concept behind noise versus signal as it relates to example today on the old faithful dataset.  

2. Define the term guassian noise and explain the observations you noted as it relates to 

