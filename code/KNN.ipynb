{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1541a9cd",
   "metadata": {},
   "source": [
    "# Week 6: kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef9b95",
   "metadata": {},
   "source": [
    "First, import your libraries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1df15b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aeaeb4",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9668f69",
   "metadata": {},
   "source": [
    "Based on the following data summary, what questions and business metric should we use? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1de9ed08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43628 entries, 0 to 43627\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        43628 non-null  int64 \n",
      " 1   job        43628 non-null  object\n",
      " 2   marital    43628 non-null  object\n",
      " 3   education  43628 non-null  object\n",
      " 4   default    43628 non-null  object\n",
      " 5   balance    43628 non-null  int64 \n",
      " 6   housing    43628 non-null  object\n",
      " 7   contact    43628 non-null  object\n",
      " 8   duration   43628 non-null  int64 \n",
      " 9   campaign   43628 non-null  int64 \n",
      " 10  pdays      43628 non-null  int64 \n",
      " 11  previous   43628 non-null  int64 \n",
      " 12  poutcome   43628 non-null  object\n",
      " 13  signed up  43628 non-null  int64 \n",
      "dtypes: int64(7), object(7)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "bank_data = pd.read_csv(\"https://raw.githubusercontent.com/UVADS/DS-3001/main/data/bank.csv\")\n",
    "bank_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0154f4",
   "metadata": {},
   "source": [
    "Now, let's check the composition of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c533699e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bank_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mbank_data\u001b[49m.marital.value_counts()   \u001b[38;5;66;03m# 3 levels\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'bank_data' is not defined"
     ]
    }
   ],
   "source": [
    "bank_data.marital.value_counts()   # 3 levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41bb1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data.education.value_counts()   # 4 levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data.default.value_counts()   # 2 levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319a9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data.job.value_counts()   # 12 levels! What should we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42620d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data.contact.value_counts()   # 3 levels -- difference between cellular and telephone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data.housing.value_counts()   # 2 levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8943c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data.poutcome.value_counts()   # 4 levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b7d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data['signed up'].value_counts()   # 2 levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433686a",
   "metadata": {},
   "source": [
    "We should collapse the variable with 12 levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17c6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "employed = ['admin', 'blue-collar', 'entrepreneur', 'housemaid', 'management',\n",
    "           'self-employed', 'services', 'technician']\n",
    "# unemployed = ['student', 'unemployed', 'unknown']\n",
    "bank_data.job = bank_data.job.apply(lambda x: \"Employed\" if x in employed else \"Unemployed\")\n",
    "bank_data.job.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f3fdea",
   "metadata": {},
   "source": [
    "### What is happening above?\n",
    "1. What is \"employed\" (variable type)? \n",
    "2. What is bank_data.job, why the .job?\n",
    "3. What is .apply(lambda x: \"Employed\" if x in employed else \"Unemployed\") doing? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca373baf",
   "metadata": {},
   "source": [
    "Now, we convert the appropriate columns to factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d7a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bank_data.info()   # check the variables\n",
    "cat = ['job', 'marital', 'education', 'default', 'housing', 'contact',\n",
    "      'poutcome', 'signed up']   # select the columns to convert\n",
    "bank_data[cat] = bank_data[cat].astype('category')\n",
    "bank_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac00691",
   "metadata": {},
   "source": [
    "### Type out what is happening in the cell above\n",
    "1. cat = [] is creating a....\n",
    "2. bank_data[cat] is....\n",
    "3. bank_data[cat].astype('category') is...\n",
    "4. bank_data.info() helps us...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec7aae",
   "metadata": {},
   "source": [
    "### Check for missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7736b325",
   "metadata": {},
   "source": [
    "Using the seaborn package, we can see the distribution of missing values. Along the x-axis, you will see the proportion of the data missing for that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.displot(\n",
    "    data=bank_data.isna().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25\n",
    ")\n",
    "# plt.savefig(\"visualizing_missing_data_with_barplot_Seaborn_distplot.png\", dpi=100)\n",
    "# the above line will same the image to your computer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e910aa19",
   "metadata": {},
   "source": [
    "**No missing data!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b26a48",
   "metadata": {},
   "source": [
    "Next, we normalize the numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e80afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = bank_data.select_dtypes(include='int64').columns\n",
    "print(numeric_cols)\n",
    "# what is going to be the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc9a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "d = scaler.fit_transform(bank_data[numeric_cols])  \n",
    "scaled_df = pd.DataFrame(d, columns=numeric_cols)  \n",
    "bank_data[numeric_cols] = scaled_df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd48135",
   "metadata": {},
   "source": [
    "### Again type out what is happening in the chunk above\n",
    "1. what is \"scaler\"\n",
    "2. what is scaler.fit_transform doing?\n",
    "3. why is (bank_data[numeric_cols])\n",
    "4. What is the third line doing?\n",
    "5. What is the last line doing?\n",
    "6. How could we improve this code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f403a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "bank_data[numeric_cols] = scaler.fit_transform(bank_data[numeric_cols])\n",
    "bank_data[numeric_cols].head()\n",
    "# no intermediate variables needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b46778",
   "metadata": {},
   "source": [
    "### Let's take a look at all the different objects we have created\n",
    "1. Dataframe \n",
    "2. list\n",
    "3. ndarray\n",
    "4. Index\n",
    "5. MinMaxScaler\n",
    "\n",
    "What's the difference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eea4bd",
   "metadata": {},
   "source": [
    "Now, we onehot encode the data -- for reference, this is the process of converting categorical variables to a usable form for a machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f6bf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_cols = bank_data.select_dtypes(include='category').columns\n",
    "#print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248f74a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for the mult-layer case, factors that have more than two levels\n",
    "cat_cols = pd.Index(['marital', 'education', 'contact', 'poutcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd73eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = pd.get_dummies(bank_data[cat_cols])\n",
    "encoded.head()   # note the new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17641d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data = bank_data.drop(cat_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data = bank_data.join(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode 'job' and 'default' to binary (1/0) across the DataFrame, why are we doing this? \n",
    "\n",
    "job_map = {'Employed': 1, 'Unemployed': 0}\n",
    "default_map = {'yes': 1, 'no': 0}\n",
    "housing_map = {'yes': 1, 'no': 0}\n",
    "\n",
    "# Recode in the main dataframe\n",
    "bank_data['job'] = bank_data['job'].map(job_map).astype('int8')\n",
    "bank_data['default'] = bank_data['default'].map(default_map).astype('int8')\n",
    "bank_data['housing'] = bank_data['housing'].map(housing_map).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cace7d8",
   "metadata": {},
   "source": [
    "The data is ready! Now, let's build our model.\n",
    "\n",
    "## Train model\n",
    "\n",
    "We'll run the kNN algorithm on the banking data. First, we'll check the prevalence of the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e86115",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data['signed up'].value_counts()[1] / bank_data['signed up'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4fd681",
   "metadata": {},
   "source": [
    "This means that at random, we have an 11.6% chance of correctly picking a subscribed individual. Let's see if kNN can do any better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b946a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X = bank_data.drop(['signed up_1'], axis=1).values   # independent variables\n",
    "y = bank_data['signed up_1'].values                  # dependent variable\n",
    "\"\"\"\n",
    "\n",
    "train, test = train_test_split(bank_data,  test_size=0.4, stratify = bank_data['signed up']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149df56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test, val = train_test_split(test, test_size=0.5, stratify=test['signed up'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1a839d",
   "metadata": {},
   "source": [
    "Now, let's train the classifier for k=9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713945dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1984)   # kNN is a random algorithm, so we use `random.seed(x)` to make results repeatable\n",
    "\n",
    "X_train = train.drop(['signed up'], axis=1).values\n",
    "y_train = train['signed up'].values\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=9)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eb18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we check the model's accuracy on the test data:\n",
    "\n",
    "X_test = test.drop(['signed up'], axis=1).values\n",
    "y_test = test['signed up'].values\n",
    "\n",
    "neigh.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb6b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we test the accuracy on our validation data.\n",
    "\n",
    "X_val = val.drop(['signed up'], axis=1).values\n",
    "y_val = val['signed up'].values\n",
    "\n",
    "neigh.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fecf81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a confusion matrix using ConfusionMatrixDisplay (plot_confusion_matrix was removed)\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(neigh, X_val, y_val, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b0d35",
   "metadata": {},
   "source": [
    "*tip: use this link to change the color scheme of your confusion matrix: https://matplotlib.org/stable/tutorials/colors/colormaps.html*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_val_pred = neigh.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e077a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val_pred, y_val))\n",
    "\n",
    "# Precision = TP / (TP + FP)\n",
    "# - Of all instances the model predicted as positive, precision is the proportion that are actually positive.\n",
    "# - High precision means few false positives (predicted positive but actually negative).\n",
    "#\n",
    "# Recall (a.k.a. Sensitivity) = TP / (TP + FN)\n",
    "# - Of all actual positive instances, recall is the proportion the model correctly identified.\n",
    "# - High recall means few false negatives (actually positive but predicted negative).\n",
    "#\n",
    "# Key difference:\n",
    "# - Precision measures correctness of positive predictions; recall measures coverage of actual positives.\n",
    "# - There is often a trade-off: raising recall (catch more positives) can lower precision (more false alarms), and vice versa.\n",
    "#\n",
    "# When to prefer which:\n",
    "# - Prioritize precision when false positives are costly (e.g., spam filter blocking legitimate mail).\n",
    "# - Prioritize recall when false negatives are costly (e.g., disease screening missing sick patients).\n",
    "#\n",
    "# The F1 score combines both: F1 = 2 * (precision * recall) / (precision + recall), useful when you want a balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd03c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we didn't get sensitivity and specificity, so we'll calculate that ourselves.\n",
    "sensitivity = 943/(943+72)   # = TP/(TP+FN)\n",
    "specificity = 7707/(7707+4)   # = TN/(TN+FP)\n",
    "print(sensitivity, specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f4ba5",
   "metadata": {},
   "source": [
    "#### Selecting the correct 'k'\n",
    "\n",
    "How does \"k\" affect classification accuracy? Let's create a function to calculate classification accuracy based on the number of \"k.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3045c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseK(k, X_train, y_train, X_test, y_test):\n",
    "    random.seed(1)\n",
    "    print(\"calculating... \", k, \"k\")    # I'll include this so you can see the progress of the function as it runs\n",
    "    class_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    class_knn.fit(X_train, y_train)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    accu = class_knn.score(X_test, y_test)\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc0f184",
   "metadata": {},
   "source": [
    "We'll test odd k values from 1 to 21. We want to create a table of all the data, so we'll use list comprehension to create the \"accuracy\" column. \n",
    "\n",
    "*remember: Python is end-exclusive; we want UP to 21 to we'll have to extend the end bound to include it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c859aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'k':list(range(1,22,2)), \n",
    "                     'accu':[chooseK(x, X_train, y_train, X_test, y_test) for x in list(range(1, 22, 2))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03815cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.sort_values(by=['accu'], ascending=False)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d23299",
   "metadata": {},
   "source": [
    "**From here, we see that the best value of k=1!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da12071",
   "metadata": {},
   "source": [
    "Let's go through the code we wrote in a bit more detail, specifically regarding the DataFrame construction.\n",
    "\n",
    "For reference, here's the line of code we wrote:\n",
    "```\n",
    "test = pd.DataFrame({'k':list(range(1,22,2)), \n",
    "                     'accu':[chooseK(x, X_train, y_train, X_test, y_test) for x in list(range(1, 22, 2))]})\n",
    "```\n",
    "\n",
    "pandas DataFrames wrap around the Python dictionary data type, which is identifiable by the use of curly brackets ({}) and key-value pairs. The keys correspond to the column names (i.e. 'k' or 'accu') while the values are a list comprised of all the values we want to include. \n",
    "\n",
    "For 'k', we made a list of the range of numbers from 1 to 22 (end exclusive), selecting only every *other* value. This is done using the syntax: `range(first_val, end_val, by=?)`. Having no `by=` value means that we select every value in that range.\n",
    "\n",
    "For 'accu', we used <a href=https://www.w3schools.com/python/python_lists_comprehension.asp>list comprehension</a>, which boils down to being loop shorthand with the output being entered into a list. We could easily re-write the code as:\n",
    "\n",
    "```\n",
    "temp = []\n",
    "for x in list(range(1, 22, 2)):\n",
    "    temp.append(chooseK(x, X_train, y_train, X_test, y_test))\n",
    "```\n",
    "\n",
    "before adding the list to the DataFrame. Evidently, the list comprehension saves time and memory, which is why we used it earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658dcba6",
   "metadata": {},
   "source": [
    "#### Now, let's graph our results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d52977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test['k'], test['accu'])\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee0cf5",
   "metadata": {},
   "source": [
    "## Adjusting the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8da990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to make a table containing: probability, expected, and actual values\n",
    "\n",
    "test_probs = neigh.predict_proba(X_test)\n",
    "test_preds = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d079b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert probabilities to pd df\n",
    "test_probabilities = pd.DataFrame(test_probs, columns = ['not_signed_up_prob', 'signed_up_prob'])\n",
    "test_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8df49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = pd.DataFrame({'actual_class': y_test.tolist(),\n",
    "                           'pred_class': test_preds.tolist(),\n",
    "                           'pred_prob': [test_probabilities['signed_up_prob'][i] if test_preds[i]==1 else test_probabilities['not_signed_up_prob'][i] for i in range(len(test_preds))]})\n",
    "# that last line is some list comprehension -- to understand that here in particular click the following link:\n",
    "# https://stackoverflow.com/questions/4260280/if-else-in-a-list-comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094554b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7983f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column about the probability the observation is in the positive class\n",
    "final_model['pos_pred'] = [final_model.pred_prob[i] if final_model.pred_class[i]==1 else 1-final_model.pred_prob[i] for i in range(len(final_model.pred_class))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95b17eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert classes to categories\n",
    "final_model.actual_class = final_model.actual_class.astype('category')\n",
    "final_model.pred_class = final_model.pred_class.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3603d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create probability distribution graph\n",
    "import seaborn as sns\n",
    "\n",
    "sns.displot(final_model, x=\"pos_pred\", kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a0196",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.pos_pred.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8e4f2",
   "metadata": {},
   "source": [
    "In most datasets, the probabilities range between 0 and 1, causing uncertain predictions. A threshold must be set for where you consider the prediction to actually be a part of the positive class. Is a 60% certainty positive? How about 40%? This is where you have more control over your model's classifications. **This is especially useful for reducing incorrect classifications that you may have noticed in your confusion matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92659fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def adjust_thres(x, y, z):\n",
    "    \"\"\"\n",
    "    x=pred_probabilities\n",
    "    y=threshold\n",
    "    z=tune_outcome\n",
    "    \"\"\"\n",
    "    thres = pd.DataFrame({'new_preds': [1 if i > y else 0 for i in x]})\n",
    "    thres.new_preds = thres.new_preds.astype('category')\n",
    "    con_mat = confusion_matrix(z, thres)  \n",
    "    print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f70b9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(final_model.actual_class, final_model.pred_class)   # original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6e15c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_thres(final_model.pos_pred, .90, final_model.actual_class)   # raise threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a94738",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_thres(final_model.pos_pred, .3, final_model.actual_class)   # lower threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e7ac3",
   "metadata": {},
   "source": [
    "## More for next week: evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e695fbbb",
   "metadata": {},
   "source": [
    "#### ROC/AUC curve\n",
    "There are a few really cool graphing options, so I'll show you a few. There are several packages in Python are interactive as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aecc456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic graph\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, final_model.pos_pred)\n",
    "auc = metrics.roc_auc_score(y_test, final_model.pos_pred)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce1e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installs dependency for next graph\n",
    "! pip install plot_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb9ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a pretty cool one\n",
    "\n",
    "from plot_metric.functions import BinaryClassification\n",
    "\n",
    "# Visualisation with plot_metric\n",
    "bc = BinaryClassification(y_test, final_model.pred_class, labels=[\"0\", \"1\"])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b07f2f",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03403b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test, final_model.pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ae43d",
   "metadata": {},
   "source": [
    "#### LogLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4719c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.log_loss(y_test, final_model.pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e26e1c",
   "metadata": {},
   "source": [
    "## Another quick example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "\n",
    "iris = data(\"iris\")\n",
    "iris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fbfc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023be467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "cols = list(iris.columns[:4])\n",
    "\n",
    "scaledIris = pd.DataFrame(scale(iris.iloc[:, :4]), index=iris.index, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e242f325",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledIris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5257315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledIris['Species'] = iris['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e5f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split datasets\n",
    "irisTrain, irisTest = train_test_split(scaledIris,  test_size=0.4, stratify = scaledIris['Species']) \n",
    "irisTest, irisVal = train_test_split(irisTest, test_size=0.5, stratify = irisTest['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78776939",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xi_train = irisTrain.drop(['Species'], axis=1)\n",
    "yi_train = irisTrain['Species']\n",
    "\n",
    "Xi_test = irisTest.drop(['Species'], axis=1)\n",
    "yi_test = irisTest['Species']\n",
    "\n",
    "Xi_val = irisVal.drop(['Species'], axis=1)\n",
    "yi_val = irisVal['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527ba982",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "iris_neigh.fit(Xi_train, yi_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d220d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_neigh.score(Xi_test, yi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89adaa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_neigh.score(Xi_val, yi_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccfba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(iris_neigh, Xi_val, yi_val, cmap='Blues')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42993be4",
   "metadata": {},
   "source": [
    "## Example using 10-k cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4810f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=10, n_repeats=3, random_state=12) \n",
    "\n",
    "X_si = scaledIris.drop(['Species'], axis=1)\n",
    "y_si = scaledIris['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ec07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cv_neigh = KNeighborsClassifier(n_neighbors=3)   # create classifier\n",
    "scores = cross_val_score(cv_neigh, X_si, y_si, scoring='accuracy', cv=rkf, n_jobs=-1)   # do repeated cv\n",
    "\n",
    "print('Accuracy: %.3f (%.3f)' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ed8531",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bdd0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more complex version so you can create a graph for testing and training accuracy (not built into the previous version)\n",
    "\n",
    "#Split arrays or matrices into train and test subsets\n",
    "Xsi_train, Xsi_test, ysi_train, ysi_test = train_test_split(X_si, y_si, test_size=0.20) \n",
    "rcv_knn = KNeighborsClassifier(n_neighbors=6)\n",
    "rcv_knn.fit(Xsi_train, ysi_train)\n",
    "\n",
    "print(\"Preliminary model score:\")\n",
    "print(rcv_knn.score(Xsi_test, ysi_test))\n",
    "\n",
    "no_neighbors = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(no_neighbors))\n",
    "test_accuracy = np.empty(len(no_neighbors))\n",
    "\n",
    "for i, k in enumerate(no_neighbors):\n",
    "    # We instantiate the classifier\n",
    "    rcv_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Fit the classifier to the training data\n",
    "    rcv_knn.fit(Xsi_train, ysi_train)\n",
    "    \n",
    "    # Compute accuracy on the training set\n",
    "    train_accuracy[i] = rcv_knn.score(Xsi_train, ysi_train)\n",
    "\n",
    "    # Compute accuracy on the testing set\n",
    "    test_accuracy[i] = rcv_knn.score(Xsi_test, ysi_test)\n",
    "\n",
    "# Visualization of k values vs accuracy\n",
    "plt.title('k-NN: Varying Number of Neighbors')\n",
    "plt.plot(no_neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(no_neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b122ae79",
   "metadata": {},
   "source": [
    "### Variable importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197f9fd6",
   "metadata": {},
   "source": [
    "There is no easy way in SKLearn to calculate variable importance for a KNN model. So, we'll use a slightly hacked-together solution.\n",
    "\n",
    "Variable importance reflects the significance one variable has on the model. If a variable is more important, that variable being removed/permuted has a larger effect on the output of the model. So, if we check the changes such permutations have, we should be able to extract the feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d7a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'sepal_length': [0], 'sepal_width': [0], 'petal_length': [0], 'petal_width': [0]}\n",
    "feat_imp = pd.DataFrame(data)\n",
    "feat_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d12968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "\n",
    "fin_knn = KNeighborsClassifier(n_neighbors=7)\n",
    "fin_knn.fit(Xsi_train, ysi_train)\n",
    "\n",
    "print(fin_knn.score(Xsi_test, ysi_test))\n",
    "plot_confusion_matrix(fin_knn, Xsi_test, ysi_test, cmap='Blues')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b859764b",
   "metadata": {},
   "source": [
    "#### change `Sepal.Length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623925fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsi_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0234cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_SL = Xsi_test.copy()   # # copy df; we don't want to alter the actual data\n",
    "perm_SL['Sepal.Length'] = np.random.permutation(perm_SL['Sepal.Length'])   # permute data\n",
    "perm_SL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_knn.score(perm_SL, ysi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30984844",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp['sepal_length'] = fin_knn.score(Xsi_test, ysi_test) - fin_knn.score(perm_SL, ysi_test)\n",
    "feat_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd4d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(fin_knn, perm_SL, ysi_test, cmap='Blues')  # what got misclassified?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd79314",
   "metadata": {},
   "source": [
    "Instead of making this repetitive, we can turn this into a function and loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751e439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureImportance(X, y, model):\n",
    "    # create dataframe of variables\n",
    "    var_imp = pd.DataFrame(columns=list(X.columns))\n",
    "    var_imp.loc[0] = 0\n",
    "    base_score = model.score(X, y)\n",
    "    for col in list(X.columns):\n",
    "        temp = X.copy()   # # copy df; we don't want to alter the actual data\n",
    "        temp[col] = np.random.permutation(temp[col])   # permute data\n",
    "        var_imp[col] = base_score - model.score(temp, y)\n",
    "        # plot_confusion_matrix(model, temp, y, cmap='Blues')  # what got misclassified?\n",
    "    print(var_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10009cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImportance(Xsi_test, ysi_test, fin_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4473e8",
   "metadata": {},
   "source": [
    "From here, we find the important variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0627126e",
   "metadata": {},
   "source": [
    "### General eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f41a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(fin_knn, Xsi_test, ysi_test, cmap='Blues')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859bbe13",
   "metadata": {},
   "source": [
    "Looks like we only misclassified one virginica as versicolor. Let's see how certain our predictions were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eef526",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris2_probs = fin_knn.predict_proba(Xsi_test)\n",
    "iris2_probs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
